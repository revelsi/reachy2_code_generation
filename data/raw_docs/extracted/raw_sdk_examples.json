[
  {
    "content": "# # Getting started with Reachy 2\n\n# In this first tutorial, we will familiarize ourselves with Reachy. We will cover how to connect to the robot and obtain basic information.\n\n# ## Connect to Reachy\n\n# First, establish a connection to your robot:\n\n```python\nfrom reachy2_sdk import ReachySDK\n\nreachy = ReachySDK(host='localhost')  # Replace localhost with your robot's IP address\n```\n\n# You can check the connection status at any time with:\n\n```python\nreachy.is_connected()\n```\n\n# Reachy is now ready for use. By default, all motors are turned off. In the next tutorial, we will learn how to move Reachy. The overall status of Reachy's motors can be checked as follows:\n\n```python\nreachy.is_on() # will return False because the motors are off by default\n```\n\n# Let's retrieve information about the robot, including mode, serial number, hardware / software versions, and battery level:\n\n```python\nreachy.info\n```\n\n# You can also access these informations independently, for example:\n\n```python\nreachy.info.battery_voltage\n```\n\n# ## Body parts\n\n# Let's take a look at Reachy's body. Reachy's arm has 7 degrees of freedom and one joint for the gripper.\n\nThe **arm** is divided into the following elements:\n- **shoulder**, consisting of 2 joints (pitch and roll)\n- **elbow**, consisting of 2 joints (yaw and pitch)\n- **wrist**, consisting of 3 joints (roll, pitch, and yaw)\n- **gripper**, consisting by default of 1 joint accessed directly at the gripper level\n\nWe refer to the shoulder, elbow, and wrist as **actuators**. A joint is essentially an axis along which the actuator can rotate.\nFor some actions, such as changing the compliancy, this is the lowest level of control you will have.\nThe default parallel gripper is a specific actuator that has only one joint, so everything is accessed at its level.\n\nThe head consists of three actuators: the **neck**, with 3 degrees of freedom (joints), and **l_antenna** and **r_antenna**, with a single joint for each of them.\n\nThe following command lists all available joints:\n\n```python\nreachy.joints\n```\n\n# The current and goal positions are also listed (i.e., the present and target angles of the joints).\nEach body part can be explored individually:\n\n```python\nreachy.r_arm.joints\n#reachy.l_arm.joints\n#reachy.head.joints\n```\n\n# ## Mobile Base\n\n# The mobile base can be accessed in the same way as the body parts:\n> Be aware that there is no mobile base in the fake mode configuration. \n\n```python\nreachy.mobile_base\n```\n\n# ## Disconnect\n\n# No action is required; simply close your terminal or notebook!\n\nIf you need to switch between robots, you can disconnect from one and then connect to another:\n\n```python\nreachy.disconnect()\n\nreachy = ReachySDK(host='localhost') # connect to a new robot with its IP address\n```",
    "metadata": {
      "source": "src/examples/1_getting_started.ipynb",
      "type": "example",
      "format": "notebook",
      "collection": "reachy2_sdk",
      "title": "1_getting_started"
    }
  },
  {
    "content": "# # Goto introduction\n\n# ReachySDK for Reachy 2 offers you methods to make movements with the arms and head, controlling the target position in several ways, choosing the duration of the movement, or even the interpolation mode. We called them **Goto**.\n\nThose methods work the same way on the arms, on the head, and on the mobile base.\n\nThe methods to use in order to control the robot are:\n-  for the arms:  \n    - **`goto()`**: depending on the parameter entered, you can control either :\n        - the joint value of each joint in degrees : *list of 7 values (joint space)*\n        - the end-effector position in the robot frame of reference : *4x4 homogeneous matrix (cartesian space)*\n    - **`translate_by()`** and **`rotate_by()`** : you can translate or rotate the position of the end-effector in space, in robot frame or gripper frame\n\n- for the head:  \n    - **`goto()`**: depending on the parameter entered, you can control either :\n        - the joint value of each head joint in degrees : *list of  3 values (joint space)*\n        - the head orientation in the robot frame : *quaternion (cartesian space)*\n        > Be careful that, between the joint and cartesian spaces, there is a 10-degree difference in pitch : to have the head looking forward, in joint space you have to put rpy = [0,10,0] whereas in cartesian space, it's the equivalent of [0,0,0].\n    \n    - **`look_at()`**: you control the head by giving a point in the robot coordinate system the head will look at\n    - **`rotate_by()`**: you can rotate the head in relation to its current position, by setting roll, pitch and yaw values in degrees, either in relation to the robot's frame of reference or to the head.\n\n- for the mobile base:\n    - **`goto()`**: you control the mobile base by giving a position to reach in the odometry frame of the mobile base\n\n\nGrippers and antennas also support goto commands:\n\n- for the grippers:\n    - **`goto()`**: you control the position or opening of the gripper\n\n- for the antennas:\n    - **`goto()`**: you control the position of the antennas\n\n\n# > The following tutorial only shows examples for the arms, head and mobile_base, but most of the description is also true for the goto commands on the grippers and antennas.\n\n# ## Initialize your robot\n\n# Connect to your robot:\n\n```python\nfrom reachy2_sdk import ReachySDK\nimport time # used for time.sleep() later in the tutorial\n\nreachy = ReachySDK(host='localhost')  #Replace localhost with your robot's IP address\n```\n\n# Turn on Reachy so the motors can be controlled, and set in the default posture :\n\n```python\nreachy.turn_on()\n\nreachy.goto_posture()\n```\n\n# `goto_posture()` is a convenient function to configure the posture of all Reachy parts at once. \n\nIt accepts the parameters : \n- *default* (i.e. `goto_posture('default')`), which gives Reachy's default pose with arms outstretched on either side of the body,\n- *elbow_90* (i.e. `goto_posture('elbow_90')`), in which Reachy has the two forearms parallel to the ground. \n\nThese standard poses can be useful when you want to start a new task from a known position.\n\n# > This example is available in [set_default_posture.py](set_default_posture.py)\n\n# ## Set your First Move\n\n# Let's move Reachy's right arm. The *goto* allows to control the 7 degrees of freedom of the arm at once (see [getting_started](1_getting_started.ipynb))\n\n```python\ngoto_1 = reachy.r_arm.goto([0, 10, -10, -90, 0, 0, 0])\n\nprint(f'goto 1 {goto_1}')\n```\n\n# This method returns an id, that you can use to get information on this movement or to cancel this movement. Store this id in a variable (*goto_1* here) to be able to use it further. All the goto methods return an id.\n\nThe parameters to give are a little different between the parts that are controlled based on joints (arms and head) and the mobile base, but let's see as both work.\n\n# ## Goto commands - arms and head\n\n# The parts that can be controlled using joints, i.e:\n- reachy.l_arm\n- reachy.r_arm\n- reachy.head\n\nused goto that are defined by 3 parameters : \n- the **joint commands**, as a list of articular degree values (7 for the arms and 3 for the head)\n- the **duration**, in seconds - *set to 2 by default*\n- the **interpolation mode**, 'linear' or 'minimum_jerk' - *set to 'minimum_jerk' by default*\n\n\n# #### Goto duration \n\nYou can give a custom duration for the execution of the movements, as shown in the examples above : \n\n```python\nreachy.head.goto([20, 20, -10], duration = 3)\nreachy.l_arm.goto([0, -10, 10, -90, 0, 0, 0], duration = 5)\n\n\n# Doing:\nreachy.l_arm.goto([0, -10, 0, 0, 0, 0, 0])\n# will lead to the same result as:\nreachy.l_arm.goto([0, -10, 0, 0, 0, 0, 0], duration = 2)\n```\n\n# > Default duration is **2 seconds**.\n\nYou **cannot set a duration to 0 second**. This will raise an exception in your code!\n\n```python\nreachy.l_arm.goto([0, 0, 0, 0, 0, 0, 0], duration = 0) # raises an exception\n```\n\n# #### Goto interpolation mode\n\n# The goto methods generates a trajectory between the present position and the goal position. This trajectory is then interpolated at a predefined frequency (100Hz) to compute all intermediary target positions that should be followed before reaching the final goal position. Depending on the interpolation mode chosen, you can have a better control over speed and acceleration.\n\nTwo interpolation modes are available when sending a goto command:\n- the **linear** interpolation mode\n- the **minimum-jerk** interpolation mode\n\nBoth trajectories start and finish at the same point but don't follow the same intermediate positions. The minimum jerk will slowly accelerate at the begining and slowly decelerate at the end. This makes the movements more natural.\n\nYou can specify the interpolation mode by setting the **`interpolation_mode`** argument when calling the method:\n\n```python\nreachy.goto_posture('default', wait = True)\nreachy.head.goto([20, 20, -10], interpolation_mode='linear')\nreachy.l_arm.goto([0, -10, 10, -90, 0, 0, 0], interpolation_mode='linear')\n```\n\n# > Default interpolation mode is **minimum_jerk**.\n\n```python\n# Doing:\nreachy.l_arm.goto([0, -10, 0, 0, 0, 0, 0])\n# will lead to the same result as:\nreachy.l_arm.goto([0, -10, 0, 0, 0, 0, 0], interpolation_mode='minimum_jerk')\n\n```\n\n# ## Goto commands - mobile base\n\n# > *Pass this section if you do not have a robot with a mobile base or if you are using the robot in fake mode*\n\nThe goto parameters for the mobile base are a little different, as you cannot ask the mobile base to reach a target position in a given time. Instead of trying to reach the given position in a given time, the robot will take as long as needed to reach its goal, or be interrupted by the timeout you can set as parameter.\n\n# The parameters are:\n- the **x** target, in meters\n- the **y** target, in meters\n- the **theta** target, in degrees by default\n- the **distance_tolerance** and **angle_tolerance**, to define how close to your target the robot must be to consider the target has been reached\n- a **timeout** value, to stop the movement if the target has been reached after a certain amount of time\n\n```python\n# Rotation to reach a 90-degrees-rotation around the odom coordinate system\nreachy.mobile_base.goto(x=0, y=0, theta=90)\n```\n\n# #### Goto tolerances\n\n# You can modify the tolerances around the goal position you want to reach. Tuning the tolerances will modify the precision of the position at arrival, but also modify the time the mobile base will take before considering its movement over. You will learn more about these tolerances in the [mobile_base tutorial](5_mobile_base.ipynb).\n\n# #### Goto timeout\n\n# You don't have any duration parameters to control the mobile base, but you can use the timeout to stop the mobile base goto after a certain amount of time.  \nThe movement is stopped if the target has not been reached after the duration of this timeout. In the case the target has been reached before the timeout is over, the timeout will have no impact.\n\n```python\n# Set back the robot in position 0\nreachy.mobile_base.goto(x=0, y=0, theta=0)\n\n# Move forward by 30cm\nreachy.mobile_base.goto(x=0.3, y=0, theta=0)\n```\n\n```python\nreachy.mobile_base.goto(x=0.6, y=0, theta=0)\n```\n\n# If we print the current position of the robot, we can it has reached the goal position:\n\n```python\nprint(f\"x: {round(reachy.mobile_base.odometry['x'], 1)}\")\nprint(f\"y: {round(reachy.mobile_base.odometry['y'], 1)}\")\nprint(f\"theta: {round(reachy.mobile_base.odometry['theta'], 1)}\")\n```\n\n# Let's do the same movement by adding a timetout to the forward goto:\n\n```python\n# Set back the robot in position 0\nreachy.mobile_base.goto(x=0, y=0, theta=0)\n\n# Move forward by 30cm, with a timeout of 0.5 seconds\nreachy.mobile_base.goto(x=0.3, y=0, theta=0, timeout=0.8)\n```\n\n# If we print the current position, we can see the robot was stopped before reaching the target:\n\n```python\nprint(f\"x: {round(reachy.mobile_base.odometry['x'], 1)}\")\nprint(f\"y: {round(reachy.mobile_base.odometry['y'], 1)}\")\nprint(f\"theta: {round(reachy.mobile_base.odometry['theta'], 1)}\")\n```\n\n# > Default timeout is **100 seconds**.\n\n# ## Goto execution\n\n# There are two important concepts to be aware of : \n- gotos are stacked for a part (i.e. they run one after another),\n- but each part is independent (i.e. a goto for the left arm will run in parallel with a goto for the right arm).\n\nAll the following section is applicable to all parts (arms, head and mobile base).\n\n# ### Goto is non-blocking for other parts \n\n# It means you can send a goto command on different parts, it won't wait for the movement to be executed on the first part to execute the other one, but will follow the timing of your code.\n\nLet's take an example with a motion sequence : \n\n- Start by returning the robot to its neutral position.\n\n```python\nreachy.goto_posture('default')\n```\n\n# - Send a goto on both arms, with a delay between them. \n\n```python\nreachy.l_arm.goto([0, 0, 10, -90, 0, 0, 15], duration = 3)\ntime.sleep(1)\nreachy.r_arm.goto([0, 0, -10, -90, 0, 0, -15], duration = 2)\n```\n\n# This sequence will take 3 seconds to execute, as the right arm will start its movement 1 second after the left arm has started its own movement. They will finish at the same time.\n\n# ### Goto is blocking and stacked for a part\n\n# It means that you can send several goto commands on a part one after another without any delay, they will be played in this order, but will wait for the previous goto to be finished.  \n\nLet's take an example with the following sequence:\n\n```python\nreachy.goto_posture('default')\nreachy.l_arm.goto([0, 0, 15, -90, 0, 0, 15], duration = 3)\nreachy.l_arm.goto([0, -10, 0, 0, 0, 0, 0], duration = 2)\nreachy.l_arm.goto([0, 0, 15, -90, 0, 0, 15], duration = 3)\n```\n\n# This sequence will take 8 seconds to execute, as each movement on the left arm will wait for the previous before starting.  \n\nNevertheless, you can still send goto commands to other parts.\n\n```python\nreachy.goto_posture('default')\n\nreachy.l_arm.goto([0, 0, 15, -90, 0, 0, 15], duration = 3)  #1\ntime.sleep(1)\nreachy.l_arm.goto([0, -10, 0, 0, 0, 0, 0], duration = 2)  #2\nreachy.l_arm.goto([0, 0, 15, -90, 0, 0, 15], duration = 3)  #3\nreachy.r_arm.goto([0, 0, -15, -90, 0, 0, -15], duration = 2)  #4\n```\n\n# This sequence will still take 8 seconds to execute:\n- commands #1, #2 and #3 are sent to the left arm. They will be stacked on the left arm, and the `time.sleep(1)` won't have any effect . When received, command #2 will simply wait 2 seconds rather than 3 secondes in the previous example.\n- commands #4 is sent on the right arm, where no movement is processed. It will then start 1 second after command #1 has started, and will then be over approximatively at the same time.\n\nThe sequence execution order is #1, #4, #2, #3.\n\n# So how can a left arm goto wait for a right arm move? That's simple using the parameter *wait* in goto functions ! \n\n### Wait parameter\n\nAs you could see earlier in the goto_posture() command, we can set the parameter *wait = True* in goto functions for the execution of the program to wait for the end of the movement before going on. \n\n\n```python\nreachy.goto_posture('default', wait = True)\nprint('Default posture : done')\nr_goto_1 = reachy.r_arm.goto([0, 5, -15, -90, 0, 0, -10], duration = 2, wait = True)\nprint('Right move : done')\nr_goto_2 = reachy.l_arm.goto([0, -5, 15, -90, 0, 0, 10], duration = 2, wait = True)\nprint('Left move : done')\nreachy.goto_posture('default', wait = True)\nprint('Default posture : done')\n```\n\n# ### Goto state\n\n# For a specific goto, you may want to know its current state. You can get information on whether the goto is finished or not using:\n\n- **`is_goto_finished()`**: return True if the movement is over, but also if it won't be played because it has been cancelled for example\n\nYou can also ask for the request sent for a specific goto with:\n\n- **`get_goto_request()`**: return the part concerned by the command, as well as the goal position and other parameters of the request\n\n\nLet's take an example:\n\n```python\ngoto_1 = reachy.l_arm.goto([0, 0, 0, -60, 0, 0, 0], duration = 3)\nif reachy.mobile_base is not None:\n    goto_2 = reachy.mobile_base.goto(0.2, 0, 0)\n\ntime.sleep(1)\n\n# Goto is currently being played\ngoto1_is_finished = reachy.is_goto_finished(goto_1)\nprint(f'After 1 second, goto 1 is finished : {goto1_is_finished}\\n')\n\ntime.sleep(3)\n\n# Goto is now over\ngoto1_is_finished = reachy.is_goto_finished(goto_1)\nprint(f'After 4 seconds, goto 1 is finished : {goto1_is_finished}')\n```\n\n# We then have for the l_arm the goto_1\n\n```python\nprint(f\"Part: {reachy.get_goto_request(goto_1).part}\")\nprint(f\"Request: {reachy.get_goto_request(goto_1).request}\")\n```\n\n# And the mobile base the second one:\n\n```python\nif reachy.mobile_base is not None:\n    print(f\"Part: {reachy.get_goto_request(goto_2).part}\")\n    print(f\"Request: {reachy.get_goto_request(goto_2).request}\")\nelse: \n    print(\"Cell content ignored, no mobile_base is available\")\n```\n\n# You get information on the part involved, the target joint values, the duration of the movement, and the interpolation mode. \n\n# ### Part execution state\n\n# As the sequence can become complex, you can get information for each part on its current status, to know which movement is being played and know which others are waiting to be played.  \nFor each part, the following methods are available:\n- **`get_goto_playing()`**: will return the id of the currently played goto on the part\n- **`get_goto_queue()`**: will return the ids of all stacked goto commands waiting to be played on the part\n\nThose methods are called at the part level, to get info on the state of the part.  \n\nLet's take an example. \n\n```python\n# Write a sequence for the left arm\ngoto_1 = reachy.l_arm.goto([0, -15, 15, -90, 0, 0, 0], duration = 3)\ngoto_2 = reachy.l_arm.goto([0, -10, 0, 0, 0, 0, 0], duration = 2)\ngoto_3 = reachy.l_arm.goto([0, -15, 15, -90, 0, 0, 0], duration = 3)\n\nprint(f'goto 1: {goto_1.id}, goto 2: {goto_2.id}, goto 3: {goto_3.id}')\n\n# Goto #1 is currently playing\ncurrent_goto = reachy.l_arm.get_goto_playing()\nprint(f'current goto : {current_goto.id}')\nprint(f'l_arm queue length: {len(reachy.l_arm.get_goto_queue())} gotos waiting to be played.')\n```\n\n# ## Goto cancellation\n\n# If you want to modify the queue of goto commands on a part, or interrupt the movement being played, you can cancel goto commands at any time.  \n\nCancellations work the same way for all parts (arms, head and mobile base)\n\n# ### Single goto cancellation\n\n# To cancel a single movement, currently playing or stacked in a part's queue, use its id and call `cancel_goto_by_id()` from reachy. It will stop the robot at its current position.\n\n```python\nreachy.goto_posture('default', wait = True)\ngoto_1 = reachy.l_arm.goto([0, 15, 15, -90, 10, 0, 0], duration = 3)\ngoto_2 = reachy.head.goto([30, 0, 0], duration = 3)\n\ntime.sleep(1)\nreachy.cancel_goto_by_id(goto_1)\n```\n\n# ### Multiple gotos cancellation\n\n# To cancel all gotos at once, you can call the `cancel_all_goto()` methods.  \nThis method can be called at the level you want to act, which can be either **reachy** or a **specific part**. \n\n# #### All gotos\n\n# For example, if you want to cancel all gotos on all parts:\n\n```python\nreachy.goto_posture('default', wait = True)\n\n# Send a sequence of gotos\nreachy.head.goto([20, 30, -10], duration = 3)\nreachy.l_arm.goto([0, 0, 0, -90, 0, 0, 0], duration = 3)\nreachy.l_arm.goto([0, 0, 0, 0, 0, 0, 0], duration = 3)\n\ntime.sleep(1.5)\n\n# Cancel all gotos\nreachy.cancel_all_goto()\n\nprint(f\"Length of l_arm goto queue : {len(reachy.l_arm.get_goto_queue())}\")\n```\n\n# All movements are cancelled, even the movement stacked in the left arm queue which will never be played.  \n\n# #### All gotos for one part\n\n# If you only want to cancel movement on the left arm:\n\n```python\nreachy.goto_posture('default', wait = True)\n\n# Send a sequence of gotos\nreachy.head.goto([20, 30, -10], duration=3)\nreachy.l_arm.goto([0, 0, 0, -90, 0, 0, 0], duration = 3)\nreachy.l_arm.goto([0, 0, 0, 0, 0, 0, 0], duration = 2)\n\ntime.sleep(1)\n\n# Cancel gotos on left arm only\nreachy.l_arm.cancel_all_goto()\n```\n\n# The movement on the head will continue, but all the movements of the left will be stopped and the left arm queue cleaned.\n\n```python\nreachy.goto_posture('default', wait=True)\nreachy.turn_off()\n```",
    "metadata": {
      "source": "src/examples/2_goto_introduction.ipynb",
      "type": "example",
      "format": "notebook",
      "collection": "reachy2_sdk",
      "title": "2_goto_introduction"
    }
  },
  {
    "content": "# # Arm and Gripper\n\n# In the previous tutorial, we explored the concept of *goto* and basic control. Now, let's delve deeper into what we can do with Reachy's arms and grippers.\n\n# ## Initialize Your Robot\n\n# First, connect to your robot:\n\n```python\nfrom reachy2_sdk import ReachySDK\nimport time\n\nreachy = ReachySDK(host='localhost')  # Replace with the actual IP address of your robot\n```\n\n# Next, we need to turn on the parts we want to use:\n\n```python\nreachy.l_arm.turn_on()\nreachy.r_arm.turn_on()\n```\n\n# Since the grippers are part of the arms, they will also be turned on. You could, of course, turn on the whole robot by calling `reachy.turn_on()` directly.\nLet's check if the arms are on:\n\n```python\nprint(reachy.r_arm.is_on())\nprint(reachy.l_arm.is_on())\n```\n\n# ## Control the arms\n\nArms can be controlled in two spaces:\n\n* the **joint space**, which allows to read and write directly the angle values of each joint of the arm\n* the **cartesian space**, which consists of controlling the end effector's position and orientation in Reachy's coordinate system\n\n> Both spaces are quite different, and **we advise not to mix them** if you are not familiar with the output.\nIn fact, values of the joint space are expressed in each actuator's coordinate system (respectively shoulder, elbow and wrist), whereas commands in cartesian space are expressed in Reachy's coordinate system\n\n# ### Joint space goal\n\n# Reachy's arm offers 7 degrees of freedom. It also gives access to one joint for the gripper.\nThe arm is divided as follows:\n- shoulder, composed of 2 joints (pitch and roll)\n- elbow, composed of 2 joints (yaw and pitch)\n- wrist, composed of 3 joints (roll, pitch and yaw)\n- gripper, composed of 1 joint (directly accessed at gripper level)\n\nWe refer to the shoulder, elbow and wrist as actuators.\nFor some actions, such as changing the compliance, it is the lowest level of control you will have.\n\nYou can inspect the details of the arm with:\n\n```python\nreachy.r_arm.joints\n```\n\n```python\nreachy.l_arm.joints\n```\n\n# You can easily access the position of each joint, **excluding the gripper**, in one call with `get_current_positions()`.\n\n```python\nreachy.r_arm.get_current_positions()\n```\n\n```python\nreachy.l_arm.get_current_positions()\n```\n\n# #### Move the arms in joint space\n\n# > **The gripper's movements are always handled separately from the other joints of the arm.**\n\n# The simplest way to move an arm is to set the angle of each joint (excluding the gripper). Define a joint positions list:\n\n```python\nr_elbow_at_90_deg = [0, 10, -15, -90, 0, 0, -5]\nl_elbow_at_90_deg = [0, -10, 15, -90, 0, 0, 5]\n```\n\n# Send the joint goal positions to the arm with `goto()`\n\n```python\nreachy.r_arm.goto(r_elbow_at_90_deg)\nreachy.l_arm.goto(l_elbow_at_90_deg, wait = True)\n```\n\n# In order to easily move a single joint, we can use the `goto()` method on a given joint:\n\n```python\nreachy.r_arm.elbow.pitch.goto(0)\n```\n\n# This method works exactly like a goto on the part. All gotos sent to joints are stacked on the part they belong to.\nFor example:\n\n```python\npart_goto_id = reachy.r_arm.goto([0, 10, -15, -90, 0, 0, -5])\njoint_goto_id = reachy.r_arm.elbow.pitch.goto(0)\n\nprint(part_goto_id)\nprint(joint_goto_id)\n\nprint(reachy.r_arm.get_goto_queue())\n```\n\n# `reachy.r_arm.elbow.pitch.goto(0)` command is stacked in r_arm goto queue.\nThe goto on the elbow will be played when the previous command sent using `goto()` is over.\n\n# The arms should have moved in a way similar to what we saw in the [goto tutorial](2_goto_introduction.ipynb). You already know that you can specify the duration or the interpolation mode of this kind of movement.\n\nWe've only seen movements expressed in joint space, i.e., defined by a set of angles. How can we know the position of the gripper in space, or how can we reach an object for which we know its position? That's where kinematics come in.\n\n# ### Kinematics\n\n# The kinematic model describes the motion of a robot in mathematical form without considering the forces and torque affecting it. It only focuses on the geometric relationship between elements.\n\nWe have defined the whole kinematic model of the arm. This means the translation and rotation required to go from one joint to the next one. \n\n[Long story](https://pollen-robotics.github.io/reachy2-docs/developing-with-reachy-2/basics/4-use-arm-kinematics/) short, there are two types of kinematics:\n- Forward kinematics: from the joint positions, the gripper pose is computed in cartesian space\n- Inverse kinematics: from a given gripper pose to reach, all joint positions are computed in joint space\n\n> You can easily use forward kinematics and inverse kinematics to switch respectively from joint space to cartesian space and from cartesian space to joint space.\n\n# #### Forward Kinematics\n\n# Each arm has a `forward_kinematics` method that computes a 4x4 pose matrix (position and orientation of the gripper in space). For instance, the previous movement left the left elbow at 90\u00b0. The position (x, y, z) of the gripper is:\n\n```python\nreachy.l_arm.forward_kinematics()[:3, 3]\n```\n\n# It is not mandatory to move the arm to compute forward kinematics. This can be done for any set of joint positions such as:\n\n```python\nreachy.l_arm.forward_kinematics([10, 0, 0, -90, 0, 0, 0])\n```\n\n# Reachy didn't move, but you know where it would have gone with an additional 10\u00b0 applied to the shoulder joint.\n\n# #### Inverse Kinematics\n\n# Inverse kinematics works in the opposite way. Let's say you want to reach an object for which you know its position. What would be the set of joint positions to provide to `goto`?\n\n```python\nimport numpy as np\ntarget = np.identity(4)\ntarget = np.array([[0, 0, -1, 0.3],\n    [0, 1, 0, 0.1],\n    [1, 0, 0, -0.3],\n    [0, 0, 0, 1]])\n```\n\n```python\njoint_positions = reachy.l_arm.inverse_kinematics(target)\njoint_positions\n```\n\n```python\nreachy.l_arm.goto(joint_positions)\n```\n\n```python\nreachy.l_arm.goto_posture(\"default\")\nreachy.l_arm.goto(target, wait = True)\n```\n\n# > All these goto are illustrated in [draw_square](draw_square.py). Check it out to see how to make Reachy draw a square with its right arm!\n\n# ### Cartesian space goal\n\n# Controlling the arm in cartesian space allows you to control the position of the gripper in Reachy's coordinate system. It is the recommended way to control the robot for grasping goals.  \nLet's go back to the *elbow_90* pose:\n\n```python\nreachy.l_arm.goto_posture('elbow_90', wait = True)\n```\n\n# You can easily access the current pose of the gripper using the previously seen method `forward_kinematics()`\n\n```python\ncurrent_pose = reachy.l_arm.forward_kinematics()\nprint(current_pose)\n```\n\n# #### Move the arms in cartesian space\n\n# To control the arm in cartesian space, use the `goto(...)` method.  \nLet's use it on the current_pose:\n\n```python\nreachy.l_arm.goto(current_pose)\n```\n\n# As you have just seen, the arm moved while the gripper remains in the exact same position and orientation: that's because the computed inverse kinematics solution is different from the joint positions we chose in joint space (`goto_posture()` is in fact a joint space method).  \n\nLet's send the arm to a new goal pose.  \nWe need to define a 4x4 pose matrix as the new goal pose for the gripper:\n\n```python\nnew_pose = current_pose.copy()\nnew_pose[0, 3] += 0.1\nprint(new_pose)\n```\n\n# This new_pose is translated 10cm forward in Reachy's coordinate system (+10cm on Reachy's x axis).  \nYou can send it to the robot:\n\n```python\nreachy.l_arm.goto(new_pose)\nreachy.l_arm.goto_posture()\n```\n\n# To simplify your life, you have access to functions to easily compute translation or rotation.  \nBut first, have a look at the interpolation space!\n\n# ### Interpolation space\n\n# Let's make things a little more complicated now.  \nSending a command in a space (joint or cartesian) does not mean the interpolation to reach the goal position is made in the same space.  \n\n***What does that mean?***  \nBy default, the interpolation (all the intermediate positions the arm is going to take before reaching the goal position) is made in joint space: if the initial position of the `r_arm.shoulder.pitch` is `30` and we want to reach a position so that `r_arm.shoulder.pitch` is `15`, the goto will calculate the interpolation from 30 to 15 for the joint, **even if the goal position was given in cartesian_space**. The movement will be executed based solely on joint interpolation, without ensuring a smooth path of the end-effector in cartesian space.\n\n> **Default interpolation space is `joint_space`**\n\n# Here is an example to go through this.  \nFrom the `elbow_90` posture, we calculate a new pose that is 20cm ahead:\n\n```python\nimport numpy as np\nfrom reachy2_sdk.utils.utils import get_pose_matrix\n\ninitial_pose = get_pose_matrix([0.25, -0.3, -0.3], [0, -90, 0])\nmodified_pose = np.copy(initial_pose)\nmodified_pose[0, 3] += 0.25\n```\n\n# We send the arm to the `elbow_90` posture first:\n\n```python\nreachy.r_arm.goto(initial_pose)\n```\n\n# Then we send the arm to the new position, 20cm ahead. Watch carefully the trajectory of the gripper when moving to the new goal position:\n\n```python\nreachy.r_arm.goto(modified_pose)\n```\n\n# The gripper is going slightly down before reaching the target. This is because the movement was interpolated in joint space.  \n\nPut back the robot in the initial_pose, and set the `interpolation_space` argument to `cartesian_space` to reach the modified goal:\n\n```python\nreachy.r_arm.goto(initial_pose)\nreachy.r_arm.goto(modified_pose, interpolation_space=\"cartesian_space\")\n```\n\n# There are 3 interpolation modes: linear, minimum_jerk and elliptical. minimum_jerk is the smoothest, so it's the default mode. However, if you want to chain movements without stopping inbetween, the linear mode is probably your best bet. The elliptical interpolation allows for curved trajectories. Let's visualize the different modes in action:\n\n```python\nreachy.r_arm.goto(initial_pose, interpolation_space=\"cartesian_space\", interpolation_mode=\"linear\")\nreachy.r_arm.goto(modified_pose, interpolation_space=\"cartesian_space\", interpolation_mode=\"linear\")\n\nreachy.r_arm.goto(initial_pose, interpolation_space=\"cartesian_space\", interpolation_mode=\"minimum_jerk\")\nreachy.r_arm.goto(modified_pose, interpolation_space=\"cartesian_space\", interpolation_mode=\"minimum_jerk\")\n\nreachy.r_arm.goto(initial_pose, interpolation_space=\"cartesian_space\", interpolation_mode=\"elliptical\", arc_direction=\"above\")\nreachy.r_arm.goto(modified_pose, interpolation_space=\"cartesian_space\", interpolation_mode=\"elliptical\", arc_direction=\"above\")\n\n\nreachy.r_arm.goto(initial_pose, interpolation_space=\"cartesian_space\", interpolation_mode=\"elliptical\", arc_direction=\"right\")\nreachy.r_arm.goto(modified_pose, interpolation_space=\"cartesian_space\", interpolation_mode=\"elliptical\", arc_direction=\"right\")\n```\n\n# The gripper is not following the same trajectory as previously, as the interpolation is now made in cartesian space.\n\n# ### Relative moves: translate_by / rotate_by\n\n# The `translate_by` and `rotate_by` methods are here to simplify simple translations and rotations. \n\nNote that if you use the `translate_by` method, which is a goto-based method, the interpolation space will be set by default to cartesian_space.\n\n# > **Default interpolation space for translate_by is `cartesian_space`**\n\n# Use the `translate_by(...)` method to send the gripper back to the previous pose, asking for a translation 10cm back (-10cm on Reachy's x axis):\n\n```python\nreachy.r_arm.translate_by(-0.25, 0, 0, frame='robot')\n```\n\n# You can easily make the gripper rotate with the `rotate_by(...)` method:\n\n```python\nreachy.r_arm.rotate_by(10, 0, 0, frame='gripper')\n```\n\n# The gripper rotates by 10 degrees around the x axis of the gripper.  \nFor both functions, you need to specify a frame:\n* setting **gripper** as frame will translate or rotate in the gripper coordinate system\n* setting **robot** as frame will translate or rotate directly in Reachy's coordinate system\n\n# If you want to compute a translation or rotation without making the robot move, you can call `get_translation_by(...)` and `get_rotation_by(...)` to get the corresponding pose 4x4 matrix:\n\n```python\nreachy.r_arm.get_translation_by(-0.1, 0.2, -0.1, frame='gripper')\n```\n\n```python\nreachy.r_arm.get_rotation_by(-10, 20, 0, frame='gripper')\n```\n\n```python\nreachy.r_arm.goto_posture()\n```\n\n# ## Gripper Control\n\n# Finally, you may want to open or close a gripper to grab an object! Use the `close` or `open` method to do so:\n> Those methods can't be set as blocking moves for now, so you need to add a waiting condition while the gripper is still moving. \n\n```python\nreachy.l_arm.gripper.close()\nwhile reachy.l_arm.gripper.is_moving():\n    time.sleep(0.1)\nreachy.l_arm.gripper.open()\n```\n\n# Of course, you can partially open the gripper, and get its current opening:\n\n```python\nreachy.l_arm.gripper.set_opening(55)\nwhile reachy.l_arm.gripper.is_moving():\n    time.sleep(0.1)\nreachy.l_arm.gripper.get_current_opening()\n```\n\n```python\nreachy.r_arm.gripper.goto(100, duration=2, interpolation_mode=\"minimum_jerk\")\nreachy.r_arm.gripper.goto(0, duration=2, interpolation_mode=\"minimum_jerk\")\nreachy.r_arm.gripper.goto(100, duration=2, interpolation_mode=\"linear\")\nreachy.r_arm.gripper.goto(0, duration=2, interpolation_mode=\"linear\")\n```\n\n# # Set robot back to compliant mode\n\n```python\nreachy.r_arm.gripper.open()\nreachy.goto_posture('default', duration=2, wait=True)\n    \nreachy.turn_off_smoothly()\n```",
    "metadata": {
      "source": "src/examples/3_arm_and_gripper.ipynb",
      "type": "example",
      "format": "notebook",
      "collection": "reachy2_sdk",
      "title": "3_arm_and_gripper"
    }
  },
  {
    "content": "# # Head control\n\n# Reachy 2's head is mounted on an Orbita3D actuator, referred to as the **neck** actuator, giving 3 degrees of freedom to control the head orientation.  \n\nBefore starting to control the head, connect to your Reachy and turn it on.\n\n# ## Initialize your robot\n\n# First connect to your robot:\n\n```python\nfrom reachy2_sdk import ReachySDK\n\nreachy = ReachySDK(host='localhost')  # Replace with the actual IP address\n```\n\n# Let's check what contains the head part:\n\n```python\nreachy.head.joints\n```\n\n# As you can see, the head is composed of **five joints**:\n- neck.roll\n- neck.pitch\n- neck.yaw\n- l_antenna\n- r_antenna\n\nThe 3 first joints belong to the same Orbita3D actuator, referred to as the **neck**.\n\nTo start, we need to turn the head on:\n\n```python\nreachy.head.turn_on()\n```\n\n# You could of course turn on the whole robot by calling `reachy.turn_on()` directly.\n\n# ## Head goto\n\n# There are several ways to control the head movements:\n- using the `look_at()`, `goto` and `rotate_by` methods, called directly at the **head** level. These methods work as in the [goto_introduction](2_goto_introduction.ipynb) example\n- controlling the joints goal positions, namely **reachy.head.neck.roll**, **reachy.head.neck.pitch** and **reachy.head.neck.yaw**.\n\n# ### look_at()\n\nYou can use the `look_at()` function to make the head look at a specific point in space. This point must be given in Reachy 2's coordinate system in **meters**. The coordinate system is the one we have seen previously:\n\n* the X axis corresponds to the forward arrow,\n* the Y axis corresponds to the right to left arrow,\n* the Z axis corresponds to the up arrow.\n\nThe origin of this coordinate system is located in the upper part of the robot trunk.\n\nIf you want Reachy to look forward, you can send it the following.\n\n```python\nreachy.head.look_at(x=0.5, y=0, z=0.2, duration=1.0, wait = True)\n```\n\n# You can use multiple *look_at* to chain head movements, or even chain them with the `goto()` function described below. As seen in the goto tutorial, the commands on the head will be stacked.\nFor example:\n\n```python\nimport time\n\nlook_right = reachy.head.look_at(x=0.5, y=-0.3, z=0.1, duration=1.0)\nlook_down = reachy.head.look_at(x=0.5, y=0, z=-0.4, duration=1.0)\nlook_left = reachy.head.look_at(x=0.5, y=0.3, z=-0.1, duration=1.0)\nlook_front = reachy.head.look_at(x=0.5, y=0, z=0, duration=1.0)\n```\n\n# The best way to understand how to use the *look_at* is to play with it. Picture a position you would like Reachy's head to be in, guess a point which could match for the *look_at* and check if you got it right!\n\n# ### goto()\n\nThe `goto()` function is another way to control the head. There is two ways to use it :\n- from the desired orientation as a quaternion (in cartesian space)\n- from joints positions (in joint space)\n\nSo, you give either a quaternion or a list of 3 degree values.\n\n\n# #### In cartesian space\n\nYou can control the head with a quaternion, in cartesian space.\n\nYou can use [pyquaternion library](https://kieranwynn.github.io/pyquaternion/) to create suitable quaternion for this method.\n\n```python\nfrom pyquaternion import Quaternion\n\nq = Quaternion(axis=[1, 0, 0], angle=3.14159265 / 4) # tilt head about 45\u00b0 to the right\nreachy.head.goto(q)\n```\n\n# #### In joint space\n\n You can directly control the joint value of the neck, giving the roll, pitch and yaw angles in degrees. The rotation is made in the order: roll, pitch, yaw, in the Orbita3D coordinate system.\n\n```python\nreachy.head.goto([15, -20, 0], duration=1.0)\n```\n\n# ### Rotate_by()\n\nYou can also control the head from its current position, by using the *rotate_by* function and specifying angular degree values in roll, pitch, yaw, either in Reachy's or head's frame. \n\n\n```python\nreachy.head.rotate_by(roll=0, pitch=0, yaw=20, frame='head')\n\nreachy.head.rotate_by(roll=-30, pitch=0, yaw=0, frame='robot')\n```\n\n# ## Read head position\n\nYou can read the head positions using : \n\n- Cartesian space : \n> `get_current_orientation()` will give the orientation as a quaternion\n\n\n- Joint space :  \n> `get_current_positions()` will give the neck's roll, pitch and yaw present_position\n\n### In cartesian space :\n\n```python\nq = reachy.head.get_current_orientation()\nprint(q)\n```\n\n# ### In joint space : \n\nIn case you feel more comfortable using roll, pitch, yaw angles rather than working with quaternions, you can retrieve those values from the **neck joints**.\n\n```python\nreachy.head.goto([20, 20, -10], wait = True)\n\nreachy.head.get_current_positions()\n```\n\n# Then, you can reset the head to default position and turn it off.\n\n```python\nreachy.head.goto_posture(common_posture=\"default\", wait=True)\n    \nreachy.turn_off_smoothly()\n```\n\n# ## Antennas goto\n\n# The antennas can be accessed through the head, using `reachy.head.l_antenna` and `reachy.head.r_antenna`:\n\n```python\nprint(reachy.head.r_antenna)\nprint(reachy.head.l_antenna)\n```\n\n# The methods to control the antennas are quite close to the one available for the head:\n- using the `goto` methods, which works like in the [goto_introduction](2_goto_introduction.ipynb) example\n- controlling the joint goal positions, namely **reachy.head.r_antenna** and **reachy.head.l_antenna**\n\n# Turn on the head in order to be able to control the antennas:\n\n```python\nreachy.head.turn_on()\n```\n\n# You can now send goto commands to the antennas:\n\n```python\nreachy.head.r_antenna.goto(20, duration=0.5)\nreachy.head.l_antenna.goto(-20, duration=0.5)\nreachy.head.r_antenna.goto(0, duration=0.5)\nreachy.head.l_antenna.goto(0, duration=0.5)\n```\n\n```python\nreachy.turn_off_smoothly()\n```",
    "metadata": {
      "source": "src/examples/4_head_control.ipynb",
      "type": "example",
      "format": "notebook",
      "collection": "reachy2_sdk",
      "title": "4_head_control"
    }
  },
  {
    "content": "# # The mobile base\n\n# Reachy 2 is mounted on a mobile base!\n\n# > Make sure you have **enough clear space around the robot** before starting the tutorial. Required space is about 1.5m around the robot in each direction.\n\n# ## Initialize your robot\n\nFirst connect to your robot:\n\n```python\nfrom reachy2_sdk import ReachySDK\nimport time\n\nreachy = ReachySDK(host='localhost')  # Replace with the actual IP\n```\n\n# Let's check what contains the mobile base part:\n\n```python\nreachy.mobile_base\n```\n\n# ## Odometry\n\n# ## Move around with gotos\n\n# The goto commands and goto-based commands described below follow all the rules you saw in the [goto introduction tutorial](2_goto_introduction.ipynb).\n\n# ### Goto and odometry\n\nThe goto function is used to place the mobile_base at a relative position and orientation to its odometry, set when the robot is switched on. To be sure, you can reset the odometry before calling the function. \n\n```python\nreachy.mobile_base.reset_odometry()\n```\n\n```python\nreachy.mobile_base.odometry\n```\n\n# Let's turn on the mobile to be able to move is around\n\n```python\nreachy.mobile_base.turn_on()\n```\n\n# The robot is currently positionned at x=0, y=0, theta=0.  \nIf you want to move forward again the robot, you need to increase the x value (value is in meters):\n\n```python\n# Move 20 cm forward\na = reachy.mobile_base.goto(x=0.2, y=0.0, theta=0.0)\n```\n\n# Now, request `goto(0, 0, 0)`. The robot will return to its previous position:\n\n```python\nreachy.mobile_base.goto(x=0.0, y=0.0, theta=0.0)\n```\n\n# All the positions are relative to the fixed odometry coordinate system of the mobile base, set at the start of the robot of after a `reset_odometry()` asked by the user.\n\nSo if you do:\n\n```python\n# Move 30cm forward, to reach x=30cm\nreachy.mobile_base.goto(x=0.3, y=0.0, theta=0.0)\n\n# Go back by 10cm, to reach x=20cm\nreachy.mobile_base.goto(x=0.2, y=0.0, theta=0.0)\n```\n\n# The mobile is first going to the position x=30cm in the odometry frame. We then ask for it to get to the position x=20cm in this same frame, so the mobile base is going backward by 10cm to reach its new target.  \n\nLet's do the same by resetting the odometry between the two commands:\n\n```python\n# Move 30cm forward, to reach x=30cm in the current odometry frame\nreachy.mobile_base.goto(x=0.3, y=0.0, theta=0.0, wait=True)\ntime.sleep(0.5)\nprint(f\"x position before odometry reset: {round(reachy.mobile_base.odometry['x'], 2)}\")\n\n# Reset odometry\nreachy.mobile_base.reset_odometry()\ntime.sleep(0.5)\nprint(f\"x position after odometry reset: {round(reachy.mobile_base.odometry['x'], 2)}\")\n\n# Move 20cm forward, to reach x=20cm in the new current odometry frame\nreachy.mobile_base.goto(x=0.2, y=0.0, theta=0.0)\n```\n\n# As we reset the odometry between the two commands, the mobile base odometry position is reset to x=0cm before the second command. It will then reach x=20cm in the new frame, so move forward by 20cm.\n\nWe recommend experimenting with this concept to get familiar.\n\n# ### Relative moves\n\n# You can also decide to assign movements to the robot based on its current position and not on its odometry. \n\nTwo methods are available to give relative orders:\n- **`translate_by()`**: to give translations orders. \n- **`rotate_by()`**: to give rotations orders  \n\nThese methods work like all gotos, and return a GoToId.  \n\nThe translation or rotation is computed based on the current position if no goto is playing, or on the position required for the last queued or playing goto in case gotos are not finished.\n\nLet's try some examples to better understand how it works.\n\n# #### translate_by()\n\n# Send the mobile base back the odometry frame origin first, and reset it:\n\n```python\na = reachy.mobile_base.goto(x=0, y=0.0, theta=0.0, wait=True, timeout=10)\ntime.sleep(0.5)\nreachy.mobile_base.reset_odometry()\n```\n\n# Now, we are going to compare a `goto()` to a `translate_by()` command.  \n\nIf we check the odometry, we will see the mobile_base at the origin of the current frame (that we have just reset):\n\n```python\ntime.sleep(0.5)\nprint(\"Odometry:\")\nprint(f\"'x': {round(reachy.mobile_base.odometry['x'], 2)}\")\nprint(f\"'y': {round(reachy.mobile_base.odometry['y'], 2)}\")\nprint(f\"'theta': {round(reachy.mobile_base.odometry['theta'], 2)}\")\n```\n\n# You can move forward to the position x=20cm by asking a translation of 20cm on the x-axis:\n\n```python\nreachy.mobile_base.translate_by(x = 0.2, y = 0.0)\n```\n\n# Because you started from the origin, the result is the same as asking a `goto(x=0.2, y=0, theta=0)`.\nIf we send this goto:\n\n```python\nreachy.mobile_base.goto(x=0.2, y=0.0, theta=0.0, wait=True, timeout=10)\n```\n\n# The mobile does not move, because we are already at this position. We can check this using the odometry:\n\n```python\ntime.sleep(0.5)\nprint(\"Odometry:\")\nprint(f\"'x': {round(reachy.mobile_base.odometry['x'], 2)}\")\nprint(f\"'y': {round(reachy.mobile_base.odometry['y'], 2)}\")\nprint(f\"'theta': {round(reachy.mobile_base.odometry['theta'], 2)}\")\n```\n\n# But if we ask a new translation of 20cm, the mobile base will go forward:\n\n```python\nreachy.mobile_base.translate_by(x = 0.2, y = 0.0, wait=True, timeout=5)\ntime.sleep(0.5)\n\n# Read odometry\nprint(\"Odometry:\")\nprint(f\"'x': {round(reachy.mobile_base.odometry['x'], 2)}\")\nprint(f\"'y': {round(reachy.mobile_base.odometry['y'], 2)}\")\nprint(f\"'theta': {round(reachy.mobile_base.odometry['theta'], 2)}\")\n```\n\n# #### rotate_by()\n\n# The `rotate_by()` method works quite the same way as the `translate_by()`, unlike it is for rotations.  \nFor example, you can go back to the initial position then rotate the mobile base. \n\n```python\n# Go back to the initial position\nreachy.mobile_base.goto(x=0.0, y=0.0, theta=0.0, wait=True)\n\n# Rotation to be at 90 degrees in the frame\nreachy.mobile_base.goto(x=0.0, y=0.0, theta=90.0, wait=True)\n```\n\n```python\ntime.sleep(0.5)\nprint(\"Odometry:\")\nprint(f\"'x': {round(reachy.mobile_base.odometry['x'], 2)}\")\nprint(f\"'y': {round(reachy.mobile_base.odometry['y'], 2)}\")\nprint(f\"'theta': {round(reachy.mobile_base.odometry['theta'], 2)}\")\n```\n\n# Now, the mobile base can be rotated 90\u00b0 from its current position, allowing to get a odometry with a theta = 0\u00b0. \n\n```python\nreachy.mobile_base.rotate_by(theta=-90.0, wait=True)\ntime.sleep(0.5)\n\n# Check the odometry\nprint(\"Odometry:\")\nprint(f\"'x': {round(reachy.mobile_base.odometry['x'], 2)}\")\nprint(f\"'y': {round(reachy.mobile_base.odometry['y'], 2)}\")\nprint(f\"'theta': {round(reachy.mobile_base.odometry['theta'], 2)}\")\n```\n\n# #### Choose the right method!\n\n# Be careful with the method you use. For example, those two sequences have completely different results:\n\n```python\nreachy.mobile_base.goto(x=0, y=0.0, theta=0.0, timeout=10)\nreachy.mobile_base.goto(x=0.2, y=0.0, theta=0.0, timeout=10)\nreachy.mobile_base.goto(x=0, y=0.4, theta=0.0, timeout=10)\nreachy.mobile_base.goto(x=0, y=0, theta=90.0, timeout=10, wait=True)\n```\n\n```python\ntime.sleep(0.5)\nprint(\"Odometry:\")\nprint(f\"'x': {round(reachy.mobile_base.odometry['x'], 2)}\")\nprint(f\"'y': {round(reachy.mobile_base.odometry['y'], 2)}\")\nprint(f\"'theta': {round(reachy.mobile_base.odometry['theta'], 2)}\")\n```\n\n```python\nreachy.mobile_base.goto(x=0, y=0.0, theta=0.0, timeout=10)\nreachy.mobile_base.translate_by(x=0.2, y=0.0, timeout=10)\nreachy.mobile_base.translate_by(x=0, y=0.4, timeout=10)\na=reachy.mobile_base.rotate_by(theta=90.0, timeout=10, wait=True)\n```\n\n```python\ntime.sleep(0.5)\nprint(\"Odometry:\")\nprint(f\"'x': {round(reachy.mobile_base.odometry['x'], 2)}\")\nprint(f\"'y': {round(reachy.mobile_base.odometry['y'], 2)}\")\nprint(f\"'theta': {round(reachy.mobile_base.odometry['theta'], 2)}\")\n```\n\n# ### Goto tolerances\n\n# Unlike the arms and head whose movements duration is based on a duration argument, a mobile base goto duration is based on the tolerances and timeout arguments you can choose.  \n\nYou can modify two different tolerances:\n- the **distance_tolerance**: defines the maximum distance to the (x, y) position in meters to consider the goto as finished (even if movement to target is not over yet)\n- the **angle_tolerance**: defines the angle distance to the theta rotation to consider the goto as finished (even if movement to target is not over yet) *- units based on the degrees argument, in degrees by default*\n\n# > Default distance_tolerance is **0.05 meter**  \n> Default angle_tolerance is **5 degrees**\n\n# Be within those tolerances will raise the flag that the goto is considered as finished, which **does not mean the movement is over**! You can start a new goto without finishing this one, but if no other goto has been sent, the mobile base will try to get as close as possible to the target.  \nAs it is easier to understand with examples, let's take some:\n\n```python\n# Going back to the base position\nreachy.mobile_base.goto(x=0, y=0.0, theta=0.0)\n```\n\n# We are first going to send a target to x=0.6m, with a tolerance of 20cm. \nPut the `wait` argument to True to wait for the *goto* to be finished:\n\n```python\nreachy.mobile_base.goto(x=0.6, y=0.0, theta=0.0, distance_tolerance=0.2, wait=True)\n\nodom_goto_end = reachy.mobile_base.odometry\nprint(\"Odometry after the goto is declared as finished:\")\nprint(f\"'x': {round(odom_goto_end['x'], 3)}\")\nprint(f\"'y': {round(odom_goto_end['y'], 3)}\")\nprint(f\"'theta': {round(odom_goto_end['theta'], 3)}\")\n\ntime.sleep(1)\nodom_move_end = reachy.mobile_base.odometry\nprint(\"Odometry after the movement finished:\")\nprint(f\"'x': {round(odom_move_end['x'], 3)}\")\nprint(f\"'y': {round(odom_move_end['y'], 3)}\")\nprint(f\"'theta': {round(odom_move_end['theta'], 3)}\")\n```\n\n# When the goto was **declared as finished**, to mobile base was **still receiving commands** to try to get as close to the target position as it could, so the **movement was not finished**. Simply, you can see the odometry values are within the tolerances, so the robot is ready to receive a new goto goal.  \n\nThis can be used when chaining gotos.  \n\nFor example, if we do this chain of gotos with the default tolerances:\n\n```python\ngoto1 = reachy.mobile_base.goto(x=0.0, y=0.0, theta=0.0)\ngoto2 = reachy.mobile_base.goto(x=0.6, y=0.0, theta=0.0)\ngoto3 = reachy.mobile_base.goto(x=-0.2, y=0.0, theta=0.0)\ngoto4 = reachy.mobile_base.goto(x=0.3, y=0.0, theta=0.0)\n\nwhile not reachy.is_goto_finished(goto1):\n    time.sleep(0.05)\nodom1 = reachy.mobile_base.odometry\nprint(\"Odometry after goto1:\")\nprint(f\"'x': {round(odom1['x'], 3)}\")\nprint(f\"'y': {round(odom1['y'], 3)}\")\nprint(f\"'theta': {round(odom1['theta'], 3)}\")\n\nwhile not reachy.is_goto_finished(goto2):\n    time.sleep(0.05)\nodom2 = reachy.mobile_base.odometry\nprint(\"Odometry after goto2:\")\nprint(f\"'x': {round(odom2['x'], 3)}\")\nprint(f\"'y': {round(odom2['y'], 3)}\")\nprint(f\"'theta': {round(odom2['theta'], 3)}\")\n\nwhile not reachy.is_goto_finished(goto3):\n    time.sleep(0.05)\nodom3 = reachy.mobile_base.odometry\nprint(\"Odometry after goto3:\")\nprint(f\"'x': {round(odom3['x'], 3)}\")\nprint(f\"'y': {round(odom3['y'], 3)}\")\nprint(f\"'theta': {round(odom3['theta'], 3)}\")\n\nwhile not reachy.is_goto_finished(goto4):\n    time.sleep(0.05)\nodom4 = reachy.mobile_base.odometry\nprint(\"Odometry after goto4:\")\nprint(f\"'x': {round(odom4['x'], 3)}\")\nprint(f\"'y': {round(odom4['y'], 3)}\")\nprint(f\"'theta': {round(odom4['theta'], 3)}\")\n```\n\n# We wait each time for the current goto to be finished before we read the odometry. As we see, the odometry is close to the target after the goto is declared as finished, as the default distance_tolerance is 5cm.  \n\nIf we do now the same with the higher tolerances:\n\n```python\ngoto1 = reachy.mobile_base.goto(x=0.0, y=0.0, theta=0.0, distance_tolerance=0.1)\ngoto2 = reachy.mobile_base.goto(x=0.6, y=0.0, theta=0.0, distance_tolerance=0.3)\ngoto3 = reachy.mobile_base.goto(x=-0.2, y=0.0, theta=0.0, distance_tolerance=0.3)\ngoto4 = reachy.mobile_base.goto(x=0.3, y=0.0, theta=0.0, distance_tolerance=0.1)\n\nwhile not reachy.is_goto_finished(goto1):\n    time.sleep(0.05)\nodom1 = reachy.mobile_base.odometry\nprint(\"Odometry after goto1:\")\nprint(f\"'x': {round(odom1['x'], 3)}\")\nprint(f\"'y': {round(odom1['y'], 3)}\")\nprint(f\"'theta': {round(odom1['theta'], 3)}\")\n\nwhile not reachy.is_goto_finished(goto2):\n    time.sleep(0.05)\nodom2 = reachy.mobile_base.odometry\nprint(\"Odometry after goto2:\")\nprint(f\"'x': {round(odom2['x'], 3)}\")\nprint(f\"'y': {round(odom2['y'], 3)}\")\nprint(f\"'theta': {round(odom2['theta'], 3)}\")\n\nwhile not reachy.is_goto_finished(goto3):\n    time.sleep(0.05)\nodom3 = reachy.mobile_base.odometry\nprint(\"Odometry after goto3:\")\nprint(f\"'x': {round(odom3['x'], 3)}\")\nprint(f\"'y': {round(odom3['y'], 3)}\")\nprint(f\"'theta': {round(odom3['theta'], 3)}\")\n\nwhile not reachy.is_goto_finished(goto4):\n    time.sleep(0.05)\nodom4 = reachy.mobile_base.odometry\nprint(\"Odometry after goto4:\")\nprint(f\"'x': {round(odom4['x'], 3)}\")\nprint(f\"'y': {round(odom4['y'], 3)}\")\nprint(f\"'theta': {round(odom4['theta'], 3)}\")\n```\n\n# We still wait for the gotos to be finished The next goto starts as soon as the tolerance of the current one is reached, so the mobile base is further to the target when switching to the next command.  \n\nWhen there is no more queued goto, the mobile base tries to reach the target position, even if the *goto* was declared finished. If we ask again for the odometry, without asking any new goto, the robo has finally reached its target:\n\n```python\ntime.sleep(1)\nodom4_bis = reachy.mobile_base.odometry\nprint(\"Odometry after goto4:\")\nprint(f\"'x': {round(odom4_bis['x'], 3)}\")\nprint(f\"'y': {round(odom4_bis['y'], 3)}\")\nprint(f\"'theta': {round(odom4_bis['theta'], 3)}\")\n```\n\n# > Note : setting the tolerances to 0 will make the target impossible to reach in most cases. You will have to wait for the goto timeout to be over before the mobile base will start another goto.\n\n# ### Goto timeout\n\n# The timeout will stop the movement whatever the current position is if the target has not been reached before the timeout time is over.  \nIn the case the target has been reached, the timeout has no effect.  \n\nContrary to the tolerances, a **goto finished by a timeout does also end the real movement on the robot**, which no more commands will be sent after the timeout and the robot will stop.  \n\n\nTo see how it works, let's send the mobile base back to its base position and then send a goto with a very low timeout:\n\n```python\n# Go back to position\nreachy.mobile_base.goto(x=0.0, y=0.0, theta=0.0, wait=True)\n\n# Use a low timeout\nreachy.mobile_base.goto(x=0.4, y=0.0, theta=90.0, timeout=0.5)\n```\n\n# \nIf we check the odometry now:\n\n```python\ntime.sleep(0.5)\nprint(\"Odometry:\")\nprint(f\"'x': {round(reachy.mobile_base.odometry['x'], 5)}\")\nprint(f\"'y': {round(reachy.mobile_base.odometry['y'], 2)}\")\nprint(f\"'theta': {round(reachy.mobile_base.odometry['theta'], 2)}\")\n```\n\n# The distance to the tolerance is still not good, but the movement has stopped after the given timeout of 5 seconds.\n\n# > Default timeout is **100 seconds**\n\n# You can also use the timeout to interrupt a goto after a certain amount of time in a given direction. For example:\n\n```python\n# Go back to base position\nreachy.mobile_base.goto(x=0, y=0.0, theta=0.0, wait=True)\n\n# Start movement torwards x=1m\ntimeout_goto = reachy.mobile_base.goto(x=1, y=0.0, theta=0.0, timeout=2)\ntic = time.time()\nwhile not reachy.is_goto_finished(timeout_goto):\n    time.sleep(0.05)\nprint(f\"goto interrupted after {round(time.time() - tic, 2)} seconds\")\n```\n\n# Be careful that the mobile does not precisely follow the expected trajectory to reach the target position.\n\n# ## Advanced usage\n\n# ### Set speed\n\n# The speed of the movement can be defined using the command `set_goal_speed()`. It requires to set all 3 target speeds *vx*, *vy* and *vtheta*.\nSend then the command to the robot with `send_speed_command()`.\n\n> **This will assign speed to the robot for 200ms**\n\n```python\nreachy.mobile_base.set_goal_speed(vx=0.5, vy=0.0, vtheta=0)\ntic=time.time()\nwhile time.time()-tic < 2:\n    reachy.mobile_base.send_speed_command()\n    time.sleep(0.01)\n```\n\n# Setting speed can be useful when replaying movements for example.\n\n# ## Free wheel\n\n# In order to be able to move easily the mobile base manually (pushing the robot for example), you can turn_off the mobile like other parts:\n\n```python\nreachy.mobile_base.turn_off()\n```",
    "metadata": {
      "source": "src/examples/5_mobile_base.ipynb",
      "type": "example",
      "format": "notebook",
      "collection": "reachy2_sdk",
      "title": "5_mobile_base"
    }
  },
  {
    "content": "# # Get images from cameras\n\n# Reachy 2 has 2 types of camera:\n\n- the **teleop** cameras, with a right and left cameras, located in Reachy 2\u2019s head and used for the teleoperation\n- the **depth** camera, equipped with a depth sensor, located in Reachy 2\u2019s torso and mainly useful for manipulation tasks\n\nEach camera can be accessed separately through reachy.cameras. Teleop cameras  have a right and left view, with the left and right sides considered from Reachy point of view, while the depth camera has a left (i.e. mono RGB) and depth view. To be able to specify the view you want to get a frame from, you will need to import CameraView:\n\n# ```python\nfrom reachy2_sdk.media.camera import CameraView\n```\n\n# ## Get images\n\n# First, connect to your robot.  \n**Do not forget to import the CameraView!**\n\n```python\nfrom reachy2_sdk.media.camera import CameraView\nfrom reachy2_sdk import ReachySDK\n\nreachy = ReachySDK(host='localhost')  # Replace with the actual IP\n```\n\n# Check the list of initialized cameras:\n\n```python\nreachy.cameras\n```\n\n# The list of initialized cameras should contain both the teleop and depth cameras.  \n\n# ### Teleop cameras\n\nTo get both views of the robot teleop cameras:\n\n```python\nl_frame, l_ts = reachy.cameras.teleop.get_frame(CameraView.LEFT)\nr_frame, r_ts = reachy.cameras.teleop.get_frame(CameraView.RIGHT)\n```\n\n# We can print the timestamp of each frame (in nanosecond)\n\n```python\nprint(f\"timestamp left frame {l_ts} - timestamp right frame {r_ts}\")\n```\n\n# Let's display the captured frame with PIL:\n\n```python\nfrom PIL import Image\n```\n\n```python\nImage.fromarray(l_frame[:,:,::-1])\n```\n\n# The camera parameters, as defined [here](https://docs.ros.org/en/melodic/api/sensor_msgs/html/msg/CameraInfo.html), are also available\n\n```python\nheight, width, distortion_model, D, K, R, P =  reachy.cameras.teleop.get_parameters(CameraView.LEFT)\nprint(f\"height: {height}\")\nprint(f\"width: {width}\")\nprint(f\"distortion model: {distortion_model}\")\nprint(f\"distortion coefficients {D}\")\nprint(f\"instrinsic matrix {K}\")\nprint(f\"rectification matrix {R}\")\nprint(f\"projection matrix {P}\")\n```\n\n# ### Depth camera\n\nThe depth camera works exactly the same as the teleop camera, but you have more elements captured. In fact, it's a RGBD camera, so you have both access to the RGB image and depth information.\n\n\n\n# #### RGB images\n\nGetting RGB images from the depth camera looks the same as from the teleop one:  simply use `get_frame()`, there is only one view.\n\n```python\nframe, ts = reachy.cameras.depth.get_frame()\n```\n\n# Let's display the captured frame with PIL:\n\n```python\nImage.fromarray(frame[:,:,::-1])\n```\n\n# As for the teleop camera, parameters are also availables\n\n```python\nheight, width, distortion_model, D, K, R, P =  reachy.cameras.depth.get_parameters()\nprint(f\"height: {height}\")\nprint(f\"width: {width}\")\nprint(f\"distortion model: {distortion_model}\")\nprint(f\"distortion coefficients {D}\")\nprint(f\"instrinsic matrix {K}\")\nprint(f\"rectification matrix {R}\")\nprint(f\"projection matrix {P}\")\n```\n\n# #### Depth information\n\nThe SR camera is a depth camera, you can then diplay a left or right **depth frame** using `get_depth_frame()`, but also the **depthmap** and the **disparity**.   \n\nYou first have to capture all, then you can read the frame and get the information you want:\n\n```python\ndepth_frame, ts = reachy.cameras.depth.get_depth_frame()\n```\n\n# Let's display the captured frame with PIL:\n\n```python\nImage.fromarray(depth_frame[:,:])\n```\n\n# If needed, camera parameters for the depth view are also available\n\n```python\nheight, width, distortion_model, D, K, R, P =  reachy.cameras.depth.get_parameters(CameraView.DEPTH)\nprint(f\"height: {height}\")\nprint(f\"width: {width}\")\nprint(f\"distortion model: {distortion_model}\")\nprint(f\"distortion coefficients {D}\")\nprint(f\"instrinsic matrix {K}\")\nprint(f\"rectification matrix {R}\")\nprint(f\"projection matrix {P}\")\n```\n\n# ## Live stream\n\n# Although we provide an optimal way to get the video stream, it is still possible to display what Reachy see through the SDK. It could be useful to feed a compute vision algorithm that do not need to run at high frequency.\n\nThis is demonstrated in a dedicated script : [cameras.py](cameras.py)",
    "metadata": {
      "source": "src/examples/6_cameras_images.ipynb",
      "type": "example",
      "format": "notebook",
      "collection": "reachy2_sdk",
      "title": "6_cameras_images"
    }
  },
  {
    "content": "# # Make some noise\n\n# Reachy 2 has two microphones located on each antenna and one speaker inside its torso. The audio API allows you to record and play audio files.\n\n***Note that, for now, the audio files are located in a temporary folder on Reachy's computer and are deleted at each reboot of the robot. The file management is very basic, allowing just a list of files in a single folder.***\n\n# ## Manage the sound files\n\n# First, connect to your robot.  \n\n```python\nfrom reachy2_sdk import ReachySDK\n\nreachy = ReachySDK(host='localhost')  # Replace with the actual IP\n```\n\n# You can first check the audio files available on Reachy.\n\n```python\nreachy.audio.get_audio_files()\n```\n\n# The list may be empty if you have just started to play with Reachy. Let's add a new audio file. Reachy is able to play wav, mp3, and ogg files. Ogg files can be downloaded [here for instance](https://getsamplefiles.com/sample-audio-files/ogg).\nMake sure to change the path name in the line below. For instance */home/name/Downloads/sample-1.ogg* or *C:\\Users\\name\\Downloads\\sample-1.ogg*\n\n```python\nreachy.audio.upload_audio_file('<path>/sample-1.ogg')\nreachy.audio.upload_audio_file('<path>/sample-4.ogg')\n```\n\n# Now these two files should be listed on Reachy:\n\n```python\nreachy.audio.get_audio_files()\n```\n\n# A file can be removed if you don't want to use it. It should no longer be in the list!\n\n```python\nreachy.audio.remove_audio_file('sample-4.ogg')\n```\n\n```python\nreachy.audio.get_audio_files()\n```\n\n# ### Play a sound\n\nOnce an audio file is uploaded onto Reachy, you can play it\n\n```python\nreachy.audio.play_audio_file('sample-1.ogg')\n```\n\n# Stop the playback whenever you want\n\n```python\nreachy.audio.stop_playing()\n```\n\n# ### Record a sound\n\nIn a similar way, a sound can be recorded using Reachy's microphones. Only the ogg extension is allowed for now. The duration of the recording, in seconds, must be set.\n\n```python\nreachy.audio.record_audio('tutorial.ogg', duration_secs=5)\n```\n\n# The audio is recorded in the background; it may be stopped at any time.\n\n```python\nreachy.audio.stop_recording()\n```\n\n# The audio file is now on Reachy's file system, and available for listening\n\n```python\nreachy.audio.get_audio_files()\n```\n\n```python\nreachy.audio.play_audio_file('tutorial.ogg')\n```\n\n# Finally, the audio file can be downloaded to your local machine.\n\n```python\nreachy.audio.download_audio_file('tutorial.ogg', '<path>')\n```",
    "metadata": {
      "source": "src/examples/7_audio.ipynb",
      "type": "example",
      "format": "notebook",
      "collection": "reachy2_sdk",
      "title": "7_audio"
    }
  },
  {
    "content": "\"\"\"Example script to display live frames from the teleoperation and depth cameras.\"\"\"\n\nimport argparse\nimport logging\n\nimport cv2\nimport numpy as np\n\nfrom reachy2_sdk import ReachySDK\nfrom reachy2_sdk.media.camera import CameraView\n\n\ndef display_teleop_cam() -> None:\n    \"\"\"Display live frames from the teleoperation camera.\n\n    This function retrieves and displays frames from the left and right\n    views of the teleoperation camera. The function terminates\n    upon a keyboard interrupt.\n\n    Raises:\n        SystemExit: If the teleop camera is not available.\n    \"\"\"\n    if reachy.cameras.teleop is None:\n        exit(\"There is no teleop camera.\")\n\n    print(f\"Left camera parameters {reachy.cameras.teleop.get_parameters(CameraView.LEFT)}\")\n    print(f\"Left camera extrinsic parameters {reachy.cameras.teleop.get_extrinsics(CameraView.LEFT)}\")\n    # print(reachy.cameras.teleop.get_parameters(CameraView.RIGHT))\n\n    try:\n        while True:\n            frame, ts = reachy.cameras.teleop.get_frame(CameraView.LEFT)\n            frame_r, ts_r = reachy.cameras.teleop.get_frame(CameraView.RIGHT)\n            print(f\"timestamps secs: left {ts} - right {ts_r}\")\n            cv2.imshow(\"left\", frame)\n            cv2.imshow(\"right\", frame_r)\n            cv2.waitKey(1)\n\n    except KeyboardInterrupt:\n        logging.info(\"User Interrupt\")\n\n\ndef display_depth_cam() -> None:\n    \"\"\"Display live frames from the depth camera.\n\n    This function retrieves and displays RGB and depth frames from the depth camera.\n    It normalizes the depth map for visualization and shows the RGB frame and normalized depth\n    frame side by side. The function exits upon a keyboard interrupt.\n\n    Raises:\n        SystemExit: If the depth camera is not available.\n    \"\"\"\n    if reachy.cameras.depth is None:\n        exit(\"There is no depth camera.\")\n\n    print(f\"Depth camera parameters {reachy.cameras.depth.get_parameters()}\")\n    print(f\"Depth camera extrinsic parameters {reachy.cameras.depth.get_extrinsics()}\")\n\n    try:\n        while True:\n            rgb, ts = reachy.cameras.depth.get_frame()\n            depth, ts_r = reachy.cameras.depth.get_depth_frame()\n            depth_map_normalized = np.empty_like(depth)\n            cv2.normalize(depth, depth_map_normalized, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n            cv2.imshow(\"frame\", rgb)\n            cv2.imshow(\"depthn\", depth_map_normalized)\n            cv2.waitKey(1)\n\n    except KeyboardInterrupt:\n        logging.info(\"User Interrupt\")\n\n\nif __name__ == \"__main__\":\n    logging.basicConfig(level=logging.INFO)\n\n    argParser = argparse.ArgumentParser(description=\"SDK camera example\")\n    argParser.add_argument(\n        \"mode\",\n        type=str,\n        choices=[\"teleop\", \"depth\"],\n    )\n    args = argParser.parse_args()\n\n    reachy = ReachySDK(host=\"localhost\")\n\n    if not reachy.is_connected:\n        exit(\"Reachy is not connected.\")\n\n    if reachy.cameras is None:\n        exit(\"There is no connected camera.\")\n\n    if args.mode == \"teleop\":\n        display_teleop_cam()\n    elif args.mode == \"depth\":\n        display_depth_cam()\n",
    "metadata": {
      "source": "src/examples/cameras.py",
      "type": "example",
      "format": "python",
      "collection": "reachy2_sdk",
      "docstring": "Example script to display live frames from the teleoperation and depth cameras."
    }
  },
  {
    "content": "\"\"\"Example of how to draw a square with Reachy's right arm.\"\"\"\n\nimport logging\nimport time\n\nimport numpy as np\nimport numpy.typing as npt\n\nfrom reachy2_sdk import ReachySDK\n\n\ndef build_pose_matrix(x: float, y: float, z: float) -> npt.NDArray[np.float64]:\n    \"\"\"Build a 4x4 pose matrix for a given position in 3D space, with the effector at a fixed orientation.\n\n    Args:\n        x: The x-coordinate of the position.\n        y: The y-coordinate of the position.\n        z: The z-coordinate of the position.\n\n    Returns:\n        A 4x4 NumPy array representing the pose matrix.\n    \"\"\"\n    # The effector is always at the same orientation in the world frame\n    return np.array(\n        [\n            [0, 0, -1, x],\n            [0, 1, 0, y],\n            [1, 0, 0, z],\n            [0, 0, 0, 1],\n        ]\n    )\n\n\ndef draw_square(reachy: ReachySDK) -> None:\n    \"\"\"Draw a square path with Reachy's right arm in 3D space.\n\n    This function commands Reachy's right arm to move in a square pattern\n    using four predefined positions (A, B, C, and D) in the world frame.\n    The square is drawn by moving the arm sequentially through these positions:\n    - A: (0.4, -0.5, -0.2)\n    - B: (0.4, -0.5, 0)\n    - C: (0.4, -0.3, 0)\n    - D: (0.4, -0.3, -0.2)\n\n    see https://pollen-robotics.github.io/reachy2-docs/developing-with-reachy-2/basics/4-use-arm-kinematics/\n    for Reachy's coordinate system\n\n    Each movement uses inverse kinematics to calculate the required joint\n    positions to achieve the target pose and then sends the commands to\n    Reachy's arm to execute the movements.\n\n    Args:\n        reachy: An instance of the ReachySDK used to control the robot.\n    \"\"\"\n    # Going from A to B\n    target_pose = build_pose_matrix(0.4, -0.5, 0)\n    ik = reachy.r_arm.inverse_kinematics(target_pose)\n    reachy.r_arm.goto(ik, duration=2.0, degrees=True)\n\n    current_pos = reachy.r_arm.forward_kinematics()\n    print(\"Pose B: \", current_pos)\n\n    # Going from B to C\n    target_pose = build_pose_matrix(0.4, -0.3, 0)\n    ik = reachy.r_arm.inverse_kinematics(target_pose)\n    reachy.r_arm.goto(ik, duration=2.0, degrees=True)\n\n    current_pos = reachy.r_arm.forward_kinematics()\n    print(\"Pose C: \", current_pos)\n\n    # Going from C to D\n    target_pose = build_pose_matrix(0.4, -0.3, -0.2)\n    ik = reachy.r_arm.inverse_kinematics(target_pose)\n    reachy.r_arm.goto(ik, duration=2.0, degrees=True)\n\n    current_pos = reachy.r_arm.forward_kinematics()\n    print(\"Pose D: \", current_pos)\n\n    # Going from D to A\n    target_pose = build_pose_matrix(0.4, -0.5, -0.2)\n    ik = reachy.r_arm.inverse_kinematics(target_pose)\n    reachy.r_arm.goto(ik, duration=2.0, degrees=True, wait=True)\n\n    current_pos = reachy.r_arm.forward_kinematics()\n    print(\"Pose A: \", current_pos)\n\n\ndef goto_to_point_A(reachy: ReachySDK) -> None:\n    \"\"\"Move Reachy's right arm to Point A in 3D space.\n\n    This function commands Reachy's right arm to move to a specified target position\n    (Point A) in the world frame, which is located at (0.4, -0.5, -0.2).\n\n    Args:\n        reachy: An instance of the ReachySDK used to control the robot.\n    \"\"\"\n    # position of point A in space\n    target_pose = build_pose_matrix(0.4, -0.5, -0.2)\n    # get the position in the joint space\n    joints_positions = reachy.r_arm.inverse_kinematics(target_pose)\n    # move Reachy's right arm to this point\n    reachy.r_arm.goto(joints_positions, duration=2, wait=True)\n\n\nif __name__ == \"__main__\":\n    print(\"Reachy SDK example: draw square\")\n\n    logging.basicConfig(level=logging.INFO)\n    reachy = ReachySDK(host=\"localhost\")\n\n    if not reachy.is_connected:\n        exit(\"Reachy is not connected.\")\n\n    print(\"Turning on Reachy\")\n    reachy.turn_on()\n\n    time.sleep(0.2)\n\n    print(\"Set to Elbow 90 pose ...\")\n    goto_ids = reachy.goto_posture(\"elbow_90\", wait=True)\n    # wait_for_pose_to_finish(goto_ids)\n\n    print(\"Move to point A\")\n    goto_to_point_A(reachy)\n\n    print(\"Draw a square with the right arm ...\")\n    draw_square(reachy)\n\n    print(\"Set to Zero pose ...\")\n    goto_ids = reachy.goto_posture(\"default\", wait=True)\n    # wait_for_pose_to_finish(goto_ids)\n\n    time.sleep(0.2)\n\n    exit(\"Exiting example\")\n",
    "metadata": {
      "source": "src/examples/draw_square.py",
      "type": "example",
      "format": "python",
      "collection": "reachy2_sdk",
      "docstring": "Example of how to draw a square with Reachy's right arm."
    }
  },
  {
    "content": "\"\"\"Example of setting Reachy to zero pose using Reachy SDK.\"\"\"\n\nimport logging\nimport time\n\nfrom reachy2_sdk import ReachySDK\n\nif __name__ == \"__main__\":\n    print(\"Reachy SDK example: set to default posture\")\n\n    # display messages from SDK\n    logging.basicConfig(level=logging.INFO)\n\n    # connect to Reachy\n    reachy = ReachySDK(host=\"localhost\")\n\n    # check if connection is successful\n    if not reachy.is_connected:\n        exit(\"Reachy is not connected.\")\n\n    print(\"Reachy basic information:\")\n    print(reachy.info)\n    print(\"Reachy joint status:\")\n    print(reachy.r_arm.joints)\n\n    print(\"Turning on Reachy...\")\n    reachy.turn_on()\n\n    time.sleep(0.2)\n\n    print(\"Set to default posture...\")\n    reachy.goto_posture(\"default\")\n\n    time.sleep(1)\n\n    exit(\"Exiting example\")\n",
    "metadata": {
      "source": "src/examples/set_default_posture.py",
      "type": "example",
      "format": "python",
      "collection": "reachy2_sdk",
      "docstring": "Example of setting Reachy to zero pose using Reachy SDK."
    }
  }
]